{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d5354de-f7b6-44ca-86e8-4c9de5bd9d4a",
   "metadata": {},
   "source": [
    "**1) What is Lasso Regression, and how does it differ from other regression techniques?**\n",
    "\n",
    "**Lasso Regression:**\n",
    "Lasso Regression (Least Absolute Shrinkage and Selection Operator) is a regularized version of linear regression.\n",
    "\n",
    "- Adds a penalty term to the linear regression cost function\n",
    "- Uses L1 regularization (sum of absolute values of coefficients)\n",
    "- Can reduce coefficients to exactly zero, performing feature selection\n",
    "\n",
    "Key differences:\n",
    "\n",
    "**vs. Ordinary Linear Regression:**\n",
    "\n",
    "- Lasso includes regularization, OLS does not\n",
    "- Lasso can handle multicollinearity better\n",
    "- Lasso can perform feature selection\n",
    "\n",
    "**vs. Ridge Regression:**\n",
    "\n",
    "- Lasso uses L1 regularization, Ridge uses L2 (sum of squared coefficients)\n",
    "- Lasso can reduce coefficients to zero, Ridge only shrinks them\n",
    "- Lasso is better for feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a6e793-6528-4161-832a-95e7ca69c9d1",
   "metadata": {},
   "source": [
    "**2) What is the main advantage of using Lasso Regression in feature selection?**\n",
    "\n",
    "The main advantage of Lasso Regression in feature selection is its ability to reduce the coefficients of less important features to exactly zero. This automatically performs feature selection by effectively eliminating irrelevant or redundant predictors from the model, resulting in a simpler, more interpretable model that focuses on the most important features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6663ac-bfb1-4f5a-bbfa-067fe185bada",
   "metadata": {},
   "source": [
    "**3) How do you interpret the coefficients of a Lasso Regression model?**\n",
    "\n",
    "Interpreting Lasso Regression coefficients:\n",
    "\n",
    "- **Non-zero coefficients:** Important features that influence the target variable.\n",
    "- **Zero coefficients:** Features seems to be unimportant and excluded from the model.\n",
    "- **Magnitude:** Larger absolute values indicate stronger influence on the target.\n",
    "- **Sign:** Positive coefficients show positive relationships, negative show inverse relationships.\n",
    "- **Comparison:** Relative importance of features can be assessed by comparing coefficient magnitudes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04bfd6d-b7a4-410a-ab90-2f3853438d27",
   "metadata": {},
   "source": [
    "**4) What are the tuning parameters that can be adjusted in Lasso Regression, and how do they affect the\n",
    "model's performance?**\n",
    "\n",
    "The main tuning parameter in Lasso Regression is the regularization strength, often denoted as λ (lambda).\n",
    "\n",
    "It is the parameter that controls the amount of shrinkage applied to coefficients.\n",
    "- Larger value increases regularization, leading to more coefficients becoming zero.\n",
    "- Smaller value reduces regularization, making the model more closer to the standard linear regression.\n",
    "\n",
    "Effects on model performance:\n",
    "- Higher λ: Increases bias, reduces variance (more simpler model, may underfit)\n",
    "- Lower λ: Decreases bias, increases variance (leading to more complex model, may overfit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8905118-3037-4832-8963-216f52238fc4",
   "metadata": {},
   "source": [
    "**5) Can Lasso Regression be used for non-linear regression problems? If yes, how?**\n",
    "\n",
    "Yes, Lasso regression can be adapted for non-linear regression problem.\n",
    "\n",
    "Here's how:\n",
    "\n",
    "**1. Feature Engineering:**\n",
    "- Create non-linear features (e.g., polynomial terms)\n",
    "- Apply lasso to expanded set of features\n",
    "\n",
    "**2. Lasso + non-linear base model:**\n",
    "- Use lasso for feature regression\n",
    "- Apply selected features to non-linear models (e.g, Decision tree)\n",
    "\n",
    "**3. Neural network with L1 Regularization:**\n",
    "- Apply lasso like penalties to deep learning architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37718f2-bb9d-4639-98fb-468cf2018a99",
   "metadata": {},
   "source": [
    "**6) What is the difference between Ridge Regression and Lasso Regression?**\n",
    "\n",
    "Ridge regression usually shrinks the features coefficients toward zero but not make it exactly zero therefore it can't be used for feature selection whereas Lasso regression can make some of the feature coefficients to be exactly zero so it can easily exclude the irrelevant features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a7d5d9-baf9-4cf3-b223-8346d95272ec",
   "metadata": {},
   "source": [
    "**7) Can Lasso Regression handle multicollinearity in the input features? If yes, how?**\n",
    "\n",
    "Yes, Lasso Regression can handle multicollinearity in input features. Here's how:\n",
    "\n",
    "**1. Feature selection:**\n",
    "- Lasso tends to select one feature from a group of correlated features\n",
    "- It sets coefficients of other correlated features to zero\n",
    "\n",
    "**2. Shrinkage:**\n",
    "- Reduces the impact of correlated features by shrinking their coefficients\n",
    "\n",
    "**3. Stability:**\n",
    "- Less sensitive to small changes in input data compared to OLS regression\n",
    "\n",
    "**4. Bias-variance tradeoff:**\n",
    "- Introduces bias but reduces variance in presence of multicollinearity\n",
    "\n",
    "**5. Automated handling:**\n",
    "- No need for manual feature elimination or complex correlation analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6280ce7-435b-4ecb-b032-732329956fb8",
   "metadata": {},
   "source": [
    "**8) How do you choose the optimal value of the regularization parameter (lambda) in Lasso Regression?**\n",
    "\n",
    "There are certain techniques by which we can choose the most optimal value of regularization parameter (lambda) such as hyperparameter tuning using GridSearchCV and RandomizedSearchCV to choose the value out of range of defined values that gives the best performance, Cross-Validation etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
